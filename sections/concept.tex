% !TeX root = ../paper.tex
% !TeX encoding = UTF-8
% !TeX spellcheck = en_US

\section{Domain Actor Database Concept}\label{sec:concept}
  Our concept is based on the idea of actor database systems as introduced by \citet{manifesto}.
  The combination of application and data tier provides considerable advantages for data-centric systems.
  This architecture allows leveraging domain and application knowledge to dynamically model the data layout, especially concerning data partitioning and replication schemes.
  This makes the database system modular, cloud-ready, and scalable.
  % add here: why is it better to use domain knowledge to partition and distribute data?

  \subsection{Domain Actors}\label{sec:dactors}
    Similar to \citet{Shah:reactdb}, we introduce a special type of actor, called \gls{dactor}, that acts as an application-defined scaling unit.
    \Glspl{dactor} can be used to model application-domain objects and encapsulate the object's state and application logic in an actor.
    Using actors for this enforces technical encapsulation of state access due to the purely private state in actors and the need of explicit asynchronous messaging between the actors.
    The encapsulation also makes it easier to reason about state changes, bugs, and other failures, as only code within the \gls{dactor} can change the corresponding state.

    % internal data management with relations
    In-memory data contained within a \gls{dactor} instance is managed in a data structure called \gls{relation}.
    A \gls{relation} is, similarly to a table in the relational database model, defined as a multiset of tuples following a predefined schema.
    Due to the similarities between \glspl{relation} and tables known from the relational database model, we want to discuss the conceptual differences between the two.
    While \glspl{relation} can be used to model much of the same information as is commonly represented using tables, the \textit{Actor Database System} and specifically the concept and framework we present relies on \glspl{dactor} as models for application domain objects.

    We consider the following example of a web application with information on films and (human) actors similar to the imdb.com or rottentomatoes.com websites.
    A traditional data layout might be comprised of two tables containing information on films and actors, respectively.
    In contrast to the relational model, our model, shown in \cref{fig:dactor_diagram}, is denormalized and distributed across two different \gls{dactor} types.
    Both, \code{Film} and \code{Actor} \gls{dactor} instances contain two \glspl{relation} and store information about a specific film or actor, respectively.
    In addition, \code{Actor} instances keep some information on related \code{Film}s, i.e. those the \code{Actor} has starred in, including the \code{Film}'s \gls{dactor} id, and vice-versa.
    This realises a many-to-many relationship between both \gls{dactor} types.

    Using \glspl{dactor} to represent discrete domain-level objects, a single \gls{dactor} instance of the type film represents a single, specific film and encapsulates all corresponding data.
    This approach to layout an application's data results in much smaller \gls{relation} sizes than typical table sizes, since each \gls{dactor} instance only stores data related to one specific domain entity, and enables many business-logic-driven approaches to scaling, data partitioning, and caching.
    The tradeoff to take into account, however, is a large number of \gls{dactor} instances encapsulating the application's data and a denormalized schema.

    \begin{figure}
      \centering

      \begin{subfigure}[b]{0.44\textwidth}
        \centering
        \includestandalone[width=\textwidth]{pictures/tikz/dactor_diagram}
        \caption{Class diagram of the \texttt{Film} \gls{dactor} type defined in the example application. It contains two \glspl{relation}.}
        \label{fig:dactor_diagram}
      \end{subfigure}\hfill
      \begin{subfigure}[b]{0.54\textwidth}
        \centering
        \scriptsize
\begin{lstlisting}[]language=Scala]
class Film(id: Id) extends Dactor(id) {
  override protected val relations = {
    Film.Info -> SingleRowRelation(Film.Info),
    Film.Cast -> RowRelation(Film.Cast)
  }
  // define Dactor behavior
  override def receive: Receive = ???
}
object Film {
  object FilmInfo extends RelationDef {
    val title = ColumnDef[String]("title")
    val description = ColumnDef[String]("description")
    val release = ColumnDef[ZonedDateTime]("release")
  }
  object Cast extends RelationDef {
    val actorId = ColumnDef[Id]("actor_id")
    val name = ColumnDef[String]("actor_name")
    val rolename = ColumnDef[String]("role_name")
  }
}
\end{lstlisting}
        \subcaption{Film Dactor type definition using the presented framework.}
        \label{lst:film_definition}
      \end{subfigure}
    \end{figure}

    % logic and processing capabilities
    As \glspl{dactor} not only contain data, but also the corresponding domain logic, computation is executed concurrently.
    This supports designing a modular and extensible database system and improves scalability.
    Actors provide single-threaded semantics, which makes enforcing constraints on data tied to one domain object stored inside a \gls{dactor} easy.
    \Glspl{relation} provide an SQL-like interface to query and manipulate the contained data, so known and proven syntax and semantics can be used to define \gls{dactor}-behavior.
    While state querying and modification within \glspl{dactor} is possible in a declarative way, the application developer can explicitly define the communication across all kinds of actors via asynchronous messages and how the \glspl{dactor} handle the said messages.

  \subsection{Communication between Domain Actors}\label{sec:dactor_comm}
    Not all computation can be done with the information residing in a single \gls{dactor}.
    Hence, communication between \glspl{dactor} is required.
    As already mentioned, inter-\gls{dactor} communication is realized via explicit, asynchronous message passing.
    This allows application developers to chose the right messaging pattern for their use case.
    The choice is heavily influenced by the data layout used for the \glspl{dactor} and sets the level of parallelization and the network-load for the computation.

    We consider three main messaging patterns for inter-\gls{dactor} communication, which are shown in \cref{fig:comp_patterns}: Cascading Computation, Sequential Computation, and Concurrent Computation.
    They are provided as messaging primitives in our framework and can be combined to create more complex message flows and computation models.
    All three patterns assume a request-response messaging schema and take a high-level message to a \gls{dactor}, lets call it \gls{dactor} A, as starting point.

    \begin{figure}
      \centering

      \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includestandalone[width=\textwidth]{pictures/tikz/cascading_computation}
        \subcaption{Cascading Computation}
        \label{fig:comp_pattern_1}
      \end{subfigure}\hfill
      \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includestandalone[width=\textwidth]{pictures/tikz/sequential_computation}
        \subcaption{Sequential Computation}
        \label{fig:comp_pattern_2}
      \end{subfigure}\hfill
      \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includestandalone[width=\textwidth]{pictures/tikz/concurrent_computation}
        \subcaption{Concurrent Computation}
        \label{fig:comp_pattern_3}
      \end{subfigure}
      \caption{Inter-\gls{dactor} communication patterns. Gray bars indicate that an actor holds state that is related to the showed message flow.}
      \label{fig:comp_patterns}
    \end{figure}

    \begin{enumerate}
      \item\label{enum:comp_pattern_1} \textbf{Cascading Computation}
        A high-level message to \gls{dactor} A, will trigger successive messages to other \glspl{dactor}, which are hidden from the original requester.
        Depending on the computation performed in \gls{dactor} A, it can send requests to another \gls{dactor} (e.\,g. \gls{dactor} B) and handle the result itself before returning the response to the initial requester.
        \Gls{dactor} B can itself send messages to other \glspl{dactor} as well.
        
        As one can see in \cref{fig:comp_pattern_1}, this pattern is comparable to function calls in \gls{oop}.
        But contrary to simple function calls, messages in this pattern are sent asynchronously.
        This means that the requesting \gls{dactor} has to manage the state of pending responses, such as actor references and intermediate results, or failure cases.
        This clutters the domain logic in the \gls{dactor} and leads to complex and error-prone code.
        In addition, each message introduces network latency and can therefore increase the overall computation time compared to a single \gls{dactor} computing the response.
        If used sparsely, this pattern supports separation of concerns and the tell-don't-ask paradigm.

      \item\label{enum:comp_pattern_2} \textbf{Sequential Computation}
        \Cref{fig:comp_pattern_2} shows the sequential computation pattern.
        It is used for computations that consist of consecutive steps, where each step depends on the previous step's result, such as filter chains.

        For this and the next messaging pattern, we introduce the concept of actor-level \glspl{functor}.
        \Glspl{functor} encapsulate the processing of a high-level request in a new, short-living actor.
        They are able to communicate with other \glspl{dactor}, track the state of pending requests and handle failure cases.
        Every actor can create a new \gls{functor} to encapsulate multiple depending requests to \glspl{dactor}.
        The \gls{functor} handles the message processing and sends the final result or a failure message back to its parent actor before stopping itself.
        This reduces the code complexity in \glspl{dactor} for handling such messages.
        This message processing abstraction is also called cameo pattern\footnote{\url{http://blog.simplex.software/the-cameo-pattern}}.

        Using a \gls{functor} to process the consecutive steps of the computational chain relieves \gls{dactor} A from dealing with intermediate state, because it is managed by the \gls{functor}.
        Each \gls{functor} only has to deal with one request-response pair at a time, which leads to a simple state and processing logic for the \gls{functor} itself.

      \item\label{enum:comp_pattern_3} \textbf{Concurrent Computation}
        This messaging pattern also makes use of \glspl{functor} to encapsulate the processing of multiple request-response pairs.
        The concurrent \gls{functor} sends messages to several \glspl{dactor} in parallel and collect the results when they are finished.
        It allows for highly parallelized computations as all involved \glspl{dactor} are messaged at the same time and calculate their responses concurrently.
        The \gls{functor} collects each individual response and returns the aggregated result to its creator.
    \end{enumerate}


  \subsection{Domain Actor Database System}\label{sec:domain_actor_database}
    A domain actor database system is the combination of \glspl{dactor} and other types of actors, which together offer an interface to other applications or clients.
    The domain actor database system is a distributed runtime for persisting data and performing computations on it.
    Each \gls{dactor} must incarnate a specific \gls{dactor} type.
    This type is defined by application developers and determines the data schema encapsulated by the \gls{dactor} and the messages it can handle (its behavior).
    \Glspl{dactor} are the only place in the system that actually have persistent state.
    Other actors are stateless or have non-durable state, such as intermediate results or actor references.
    These actors can interact with the \glspl{dactor} via the defined messages and represent application services or components of the infrastructure layer.
    
    To develop such a system, we can decompose our application into encapsulated domain objects.
    In contrast to traditional entities in the relational model, domain objects should consider the most common query loads to encapsulate the needed information.
    Those domain objects can be modeled as \glspl{dactor} and consist of a data schema and behavior.
    During this process, we have to keep our requirements regarding query patterns and scaling in mind.
    Those requirements will influence the domain decomposition and the messaging patterns used.
    The entry points to our application are stateless actors on top of the \glspl{dactor}, which provide high throughput and can be scaled out easily.
    They act as routers for incoming requests and orchestrate computations.
