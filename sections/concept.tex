% !TeX root = ../paper.tex
% !TeX encoding = UTF-8
% !TeX spellcheck = en_US

\section{Domain Actor Database Framework}\label{sec:concept}
  Our actor databases system consists of two building blocks: \emph{domain actors} and \emph{\glspl{functor}}. These two concepts allow for the definition of application data within the application itself. Since both are based on actor model principles, they make the database system modular, cloud-ready, and scalable. In this section, we introduce both domain actors and \glspl{functor}.
  
%  Our concept is based on the idea of actor database systems as introduced by \citet{manifesto}.
%  The combination of application and data tier provides considerable advantages for data-centric systems.
%  This architecture allows leveraging domain and application knowledge to dynamically model the data layout, especially concerning data partitioning and replication schemes.
%  This makes the database system modular, cloud-ready, and scalable.
  % add here: why is it better to use domain knowledge to partition and distribute data?

  \subsection{Domain Actors -- Encapsulation of Data}\label{sec:dactors}
    Similar to \citet{Shah:reactdb}, we introduce a special type of actor, called \gls{dactor}, that acts as an application-defined scaling unit.
    \Glspl{dactor} can be used to model application-domain objects and encapsulate the object's state and application logic in an actor.
    Using actors for this enforces technical encapsulation of state access due to the purely private state in actors and the need of explicit asynchronous messaging between the actors.
    The encapsulation also makes it easier to reason about state changes, bugs, and other failures, as only code within the \gls{dactor} can change the corresponding state.

    % internal data management with relations
    In-memory data contained within a \gls{dactor} instance is managed in a data structure called \emph{\gls{relation}}.
    One \gls{dactor} can contain multiple \glspl{relation}.
    A \gls{relation} is, similarly to a table in the relational database model, defined as a multiset of tuples following a predefined schema.
    \Glspl{relation} provide an SQL-like interface to query and manipulate the contained data, so known and proven syntax and semantics can be used to define \gls{dactor}-behavior.
    \Glspl{relation} form a typed, \gls{dactor}-internal data model.
    Using \glspl{dactor} to implement a database leads to a modeling approach that is different to Entity-relationship modeling.
    The following example discusses the conceptual differences between the two in more detail.

    We consider the example of a web application with information on movies similar to the imdb.com or rottentomatoes.com websites.
    A standard query for those websites is to display a film with its description and cast.
    A traditional data layout might be comprised of two entities: \textit{Film} containing the film's ID, title, description and release date and \textit{Actor} containing the actor's ID and name.
    Those two entities might be in a N-to-M relation (\textit{Cast}) with an attribute showing the actor's role in the film.
    In contrast to the relational model, our model, shown in \cref{fig:film_diagram}, consists of one \gls{dactor} type and two \glspl{relation} and is denormalized.
    The information contained in the \textit{Actor} entity is distributed across the \code{Cast} \glspl{relation}.
    This allows us to answer the standard queries from one single actor instance without needing to join the answers from different, possibly physically distributed \gls{dactor} instances.

    This approach to layout an application's data results in much smaller data sizes per \gls{dactor} compared to typical database tables and enables many business-logic-driven approaches to scaling, data partitioning, and caching.
    The trade-off, however, is a large number of \gls{dactor} instances and a (partially) denormalized schema.

    \begin{figure}
      \centering

      \begin{subfigure}[b]{0.44\textwidth}
        \centering
        \includestandalone[width=\textwidth]{pictures/tikz/dactor_diagram}
        \caption{Graphical representation of the \texttt{Film} \gls{dactor} type definition.}
        \label{fig:film_diagram}
      \end{subfigure}\hfill
      \begin{subfigure}[b]{0.54\textwidth}
        \centering
        \scriptsize
\begin{lstlisting}[language=Scala]
class Film(id: DactorId) extends Dactor(id) {
  override protected val relations = {
    Film.Info -> SingleRowRelation(Film.Info),
    Film.Cast -> RowRelation(Film.Cast)
  }
  override def receive: Receive =  //Dactor behavior
}
object Film {
  object FilmInfo extends RelationDef {
    val title = ColumnDef[String]("title")
    val description = ColumnDef[String]("description")
    val release = ColumnDef[ZonedDateTime]("release")
  }
  object Cast extends RelationDef {
    val actorId = ColumnDef[DactorId]("actor_id")
    val name = ColumnDef[String]("actor_name")
    val rolename = ColumnDef[String]("role_name")
  }
}
\end{lstlisting}
        \subcaption{Example code using our framework.}
        \label{lst:film_definition}
      \end{subfigure}
      \caption[\texttt{Film} Dactor type definition with two relations of the example application.]{\code{Film} \gls{dactor} type definition with two relations from the example application.}
      \label{fig:film_dactor_definition}
    \end{figure}

    % logic and processing capabilities
    As \glspl{dactor} not only contain data, but also the corresponding domain logic, computation is executed concurrently.
    Actors provide single-threaded semantics, which makes enforcing constraints on data stored inside one \gls{dactor} easy.
    While state querying and modification within \glspl{dactor} is possible in a declarative way, the application developer can explicitly define the communication across all kinds of actors via asynchronous messages.
    The explicit messaging differentiates \glspl{dactor} from \citet{Shah:reactdb}'s reactors, as reactors can be used as relational entities and hide the message passing from the developer.
    
    To illustrate the definition of a \code{Dactor} in code, we show the definition of \code{Film}'s data model in \cref{lst:film_definition}.
    Developers can model the application's domain objects by defining \gls{dactor} types as subclasses of the framework-provided \code{Dactor} class in a declarative way.
    Instances of such user-defined \gls{dactor} types are managed by the framework and are available for messaging in a consistent namespace.
    Using the column's predefined data types, all functions support compile-time type-safety.
    Due to the \gls{dactor} system sharing the application's runtime and programming environment, these data or object types are equal to the types handled in any application logic.
    Thus, this approach helps eliminate the impedance mismatch between application logic and data tier with regard to handled data types and object (de-)serialization.

  \subsection{Functors -- Encapsulation of Queries}
    \Glspl{dactor} can answer queries via explicit, asynchronous messaging, {i.e.}, they answer a query with their local data.
    Sometimes, however, queries need be answered by several actors.
    In such cases, it makes sense to encapsulate the processing in a new, short-living actor that we call \gls{functor}.
    \Glspl{functor} are the framework's concepts that enable inter-\gls{dactor} communication and computations.
    They communicate with (usually multiple) \glspl{dactor}, track the completion of a query, handle the state of pending requests, and resolve failure cases.
    Every actor can create a new \gls{functor} to encapsulate multiple requests to \glspl{dactor}.
    The \gls{functor} handles the message processing and sends the final result or a failure message back to its creator.
    Since all Akka actors live in hierarchical parent-child relationships, \glspl{functor} are always created by an actor as a child.
    This Akka-specific hierarchical relationship enables notifying the calling actor even in case of unforeseen crashes of the \gls{functor} themselves, which in turn allows to trigger error handling, e.g. retrying the \gls{functor} execution.

%  \subsection{Comunication Patterns for Domain Actors}\label{sec:dactor_comm}
%    Not all computation can be done with the information residing in a single \gls{dactor}.
%    Hence, communication between \glspl{dactor} is required.
%    Explicit, asynchronous message passing allows application developers to chose the right messaging pattern for their use case.
%    The choice is heavily influenced by the data layout used for the \glspl{dactor} and sets the level of parallelization and the network-load for the computation.
    In our actor database system, we consider three messaging patterns for inter-\gls{dactor} communication, which are shown in \cref{fig:comp_patterns}.
    These patterns are provided as messaging primitives by the framework and can be combined to create more complex message flows and computational models:

    \begin{figure}
      \centering
      \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includestandalone[width=\textwidth]{pictures/tikz/cascading_computation}
        \subcaption{Cascading Computation}
        \label{fig:comp_pattern_1}
      \end{subfigure}\hfill
      \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includestandalone[width=\textwidth]{pictures/tikz/sequential_computation}
        \subcaption{Sequential Computation}
        \label{fig:comp_pattern_2}
      \end{subfigure}\hfill
      \begin{subfigure}[t]{0.32\textwidth}
        \centering
        \includestandalone[width=\textwidth]{pictures/tikz/concurrent_computation}
        \subcaption{Concurrent Computation}
        \label{fig:comp_pattern_3}
      \end{subfigure}
      \caption{Inter-\gls{dactor} communication patterns. Gray bars indicate that an actor holds state that is related to the showed message flow.}
      \label{fig:comp_patterns}
    \end{figure}

      \textbf{Cascading Computation} is a pattern where a high-level message to an initial \gls{dactor} (\gls{dactor} A) triggers successive messages to other \glspl{dactor}, which are hidden from the original requester.
      Following \glspl{dactor} can also trigger further messages themselves.
      As one can see in \cref{fig:comp_pattern_1}, this pattern is comparable to function calls in Object-oriented Programming.
      But contrary to simple function calls, messages in this pattern are sent asynchronously.
      This means that the requesting \gls{dactor} has to manage the state of pending responses.
      This clutters the domain logic in the \gls{dactor} and leads to complex and error-prone code.
      If used sparsely, this pattern supports separation of concerns and the tell-don't-ask paradigm.

      \textbf{Sequential Computation} is used for queries that consist of consecutive steps, where each step depends on the previous step's result, such as filter chains.
      This pattern can be implemented via the aforementioned \glspl{functor}.
      Using a \gls{functor} to process the consecutive steps of the computational chain relieves \gls{dactor} A from dealing with intermediate state, because it is managed by the \gls{functor}.
      Each \gls{functor} deals with only one request-response pair at a time, which leads to simple state and processing logic for the \gls{functor} itself.

      \textbf{Concurrent Computation} is a another messaging pattern based on \glspl{functor} to encapsulate the processing of multiple request-response pairs.
      The concurrent \gls{functor} sends messages to several \glspl{dactor} in parallel and collects the results when they are finished to forward them to its creator.
      It allows for highly parallelized computations as all involved \glspl{dactor} are messaged at the same time and calculate their responses concurrently.
      
    In summary, explicit message handling in \glspl{dactor} is used to implement the cascading communication pattern; sequential and concurrent \glspl{functor} are the framework's concepts to enable inter-\gls{dactor} communication and computations.
    Returning to the web application example, we now want to add a new film to the database using the \gls{functor} concept.
    This involves changes to a new \code{Film} and the corresponding \code{Studio} \gls{dactor} instances.
    We can combine the concurrent and sequential \glspl{functor} to implement this functionality, which is displayed in \cref{fig:functor_diagram}.
    Both sequential \glspl{functor} are comprised of two subsequent steps:
    They retrieve information from one \gls{dactor} to update the other one.
    They are independent of each other, so they can be executed in parallel, which is done by using the concurrent \gls{functor}.
    It only sends a successful response to its caller after both sequential \glspl{functor} have sent their responses to the concurrent \gls{functor}.
    
    \begin{figure}
      \centering
      \includestandalone[width=\textwidth]{pictures/tikz/functor_diagram}
      \caption{Component diagram indicating the message flow through \gls{functor} objects and their supervision by the calling actor. Arrow and dashed arrow pairs indicate corresponding request and response messages. The outgoing requests of each sequential \gls{functor} are numbered to indicate their order.}
      \label{fig:functor_diagram}
    \end{figure}      
      
    \subsection{System Details}\label{subsec:framework_discussion}
      \emph{Data partitioning} in an actor database system differs fundamentally from common partitioning techniques used in relational databases.
      While large tables are typically partitioned based on a specific column's value or the hash thereof, our framework provides \glspl{dactor} as entities for data encapsulation and partitioning.
      \Glspl{dactor} can be provisioned across multiple virtual runtimes and physical machines, because every \gls{dactor} instance is independent of the others and the only mean of communication is message passing.
      As such, they provide flexible, fine-grained data partitioning based on application needs.
      
      The distributed nature of the database system introduces the new problem of partition or \emph{actor discovery}.
      The framework maintains a unified namespace, in which each \gls{dactor} instance is identified by its \gls{dactor} type and a unique ID.
      In fact, querying a specific \gls{dactor} just requires obtaining the messaging address from the name-service and sending a message to it.
      In case of a multi-node deployment, this is complemented by Akka's Cluster Sharding component, which routes the messages to the right physical host.
      
      Finally, \emph{failure handling}, especially with regard to computations relying on multiple \glspl{dactor}' data, requires careful monitoring due to \gls{dactor} distribution.
      Building on Akka's parent-child supervision concept, our framework allows for transparent failure handling configurations.
      Failures can be handled within \glspl{dactor} if appropriate.
      In case of multi-\gls{dactor} queries a fail-fast approach is chosen to allow calling actors to react to exceptions in a timely manner.